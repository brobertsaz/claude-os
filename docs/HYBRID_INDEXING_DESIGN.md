# Claude OS Hybrid Indexing System Design

**Author:** Claude (for Claude!)
**Date:** 2025-10-31
**Status:** Design Phase

## Problem Statement

Current Claude OS indexing is too slow for large codebases:
- example-app project (Rails, 10k+ files) = 3-5 hours to index
- Generates embeddings for EVERY file and chunk
- Must complete before Claude can start working
- Blocks productive coding sessions

## Inspiration: Aider's Approach

Aider solves this with tree-sitter based structural indexing:
- Parse files with tree-sitter (no LLM calls)
- Extract symbols only (signatures, not full content)
- Build dependency graph + PageRank scoring
- Token-budget aware repo map
- **Result: 10k files indexed in ~30 seconds**

## Solution: Hybrid + Two-Phase System

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Claude OS Indexing v2.0                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Phase 1: Structural Index (tree-sitter)                    â”‚
â”‚  â”œâ”€ Speed: 30 seconds for 10k files                         â”‚
â”‚  â”œâ”€ Output: Symbol map + dependency graph                   â”‚
â”‚  â”œâ”€ Storage: {project}-code_structure KB                    â”‚
â”‚  â”œâ”€ Use: "Where is X?", "What depends on Y?"               â”‚
â”‚  â””â”€ Ready: Immediately usable                               â”‚
â”‚                                                              â”‚
â”‚  Phase 2: Semantic Index (selective embeddings)             â”‚
â”‚  â”œâ”€ Speed: 20-30 minutes (vs 3-5 hours)                    â”‚
â”‚  â”œâ”€ Scope: Top 20% by PageRank + docs + recent changes     â”‚
â”‚  â”œâ”€ Storage: {project}-project_index KB                     â”‚
â”‚  â”œâ”€ Use: "How does auth work?", "Explain this pattern"     â”‚
â”‚  â””â”€ Ready: Background job, optional                         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technical Design

### 1. Tree-Sitter Indexer Module

**File:** `app/core/tree_sitter_indexer.py`

**Key Classes:**

```python
class Tag:
    """Represents a code symbol (class, function, variable)."""
    file: str
    name: str
    kind: str  # 'class', 'function', 'method', 'variable'
    line: int
    signature: str
    importance: float  # PageRank score

class DependencyGraph:
    """NetworkX MultiDiGraph of file dependencies."""
    nodes: List[str]  # Files
    edges: List[Tuple[str, str, dict]]  # (from_file, to_file, metadata)

class TreeSitterIndexer:
    """Main indexer using tree-sitter."""

    def parse_file(file_path: str, language: str) -> List[Tag]:
        """Parse file and extract symbols."""

    def build_graph(tags: List[Tag]) -> DependencyGraph:
        """Build dependency graph from tags."""

    def rank_symbols(graph: DependencyGraph, personalization: dict) -> List[Tag]:
        """Apply PageRank to score symbol importance."""

    def generate_repo_map(ranked_tags: List[Tag], token_budget: int) -> str:
        """Create compact repo map fitting token budget."""

    def index_directory(project_path: str) -> RepoMap:
        """Main entry point: index entire directory."""
```

**Dependencies:**

```python
tree-sitter==0.21.0
py-tree-sitter-languages==1.10.2  # Pre-built binaries for 40+ languages
networkx==3.2.1  # For dependency graphs + PageRank
```

**Caching Strategy:**

```python
# SQLite cache for parsed tags (like Aider)
cache_key = f"{file_path}:{mtime}:{size}"
if cache.get(cache_key):
    return cached_tags
else:
    tags = parse_file(file_path)
    cache.set(cache_key, tags)
    return tags
```

### 2. PageRank Scoring

**Algorithm:** Same as Aider's approach

```python
def rank_symbols(graph, personalization=None):
    """
    Apply PageRank with personalization.

    Personalization factors:
    - Files in chat context: 50x boost
    - Recently modified files: 10x boost
    - Well-named identifiers (8+ chars): 10x boost
    - Referenced identifiers: 5x boost
    """
    if personalization is None:
        personalization = {}

    ranked = nx.pagerank(
        graph,
        weight="weight",
        personalization=personalization,
        max_iter=100
    )

    return sorted(ranked.items(), key=lambda x: x[1], reverse=True)
```

### 3. Token-Budget Binary Search

**Goal:** Fit most important symbols in 1024-4096 token budget

```python
def fit_to_budget(ranked_tags, max_tokens=1024):
    """
    Binary search to find max tags fitting token budget.
    Accept within 15% error margin.
    """
    lower, upper = 0, len(ranked_tags)
    best_tree = ""
    best_tokens = 0
    ok_err = 0.15  # 15% error margin

    while lower <= upper:
        mid = (lower + upper) // 2
        tree = format_repo_map(ranked_tags[:mid])
        num_tokens = count_tokens(tree)

        if num_tokens <= max_tokens:
            if num_tokens > best_tokens:
                best_tree = tree
                best_tokens = num_tokens
            lower = mid + 1
        else:
            upper = mid - 1

        # Accept if within error margin
        if abs(num_tokens - max_tokens) / max_tokens <= ok_err:
            break

    return best_tree
```

### 4. Selective Semantic Indexing

**Strategy:** Only embed high-value files

```python
def select_files_for_embedding(ranked_tags, project_path):
    """
    Select files for semantic indexing based on importance.

    Criteria:
    - Top 20% by PageRank score
    - All documentation files (*.md, *.txt)
    - Recently modified (git log --since="30 days ago")
    - User-specified critical paths
    """
    files_to_embed = set()

    # Top 20% by PageRank
    top_20_percent = int(len(ranked_tags) * 0.2)
    for tag in ranked_tags[:top_20_percent]:
        files_to_embed.add(tag.file)

    # All docs
    docs = find_files(project_path, patterns=["*.md", "*.txt", "*.rst"])
    files_to_embed.update(docs)

    # Recently modified
    recent = git_recent_files(project_path, days=30)
    files_to_embed.update(recent)

    return list(files_to_embed)
```

### 5. New API Endpoints

**File:** `mcp_server/server.py`

```python
@app.post("/api/kb/{kb_name}/index-structural")
async def index_structural(kb_name: str, project_path: str):
    """
    Phase 1: Fast tree-sitter structural indexing.
    Returns in ~30 seconds for 10k files.
    """
    indexer = TreeSitterIndexer()
    repo_map = indexer.index_directory(project_path)

    # Store in code_structure KB
    structure_kb = f"{kb_name}-code_structure"
    save_repo_map(structure_kb, repo_map)

    return {
        "status": "success",
        "repo_map_size": len(repo_map.tags),
        "time_taken": "30s",
        "ready": True
    }

@app.post("/api/kb/{kb_name}/index-semantic")
async def index_semantic(kb_name: str, project_path: str, selective: bool = True):
    """
    Phase 2: Semantic embedding (optional, background job).
    If selective=True, only embeds top 20% + docs.
    """
    if selective:
        # Get structural index first
        structure_kb = f"{kb_name}-code_structure"
        repo_map = load_repo_map(structure_kb)
        files = select_files_for_embedding(repo_map.tags, project_path)
    else:
        files = find_all_code_files(project_path)

    # Queue background job
    job = queue_embedding_job(kb_name, files)

    return {
        "status": "queued",
        "job_id": job.id,
        "files_to_embed": len(files),
        "estimated_time": f"{len(files) * 0.2 / 60:.0f} minutes"
    }

@app.get("/api/kb/{kb_name}/repo-map")
async def get_repo_map(
    kb_name: str,
    token_budget: int = 1024,
    personalization: dict = None
):
    """
    Get compact repo map for Claude's prompt context.
    """
    structure_kb = f"{kb_name}-code_structure"
    repo_map = load_repo_map(structure_kb)

    # Apply personalization if provided
    if personalization:
        repo_map.rerank(personalization)

    # Fit to token budget
    compact_map = fit_to_budget(repo_map.tags, token_budget)

    return {
        "repo_map": compact_map,
        "token_count": count_tokens(compact_map),
        "total_symbols": len(repo_map.tags)
    }
```

## Query Strategy

**How Claude uses the hybrid index:**

### 1. Session Start

```
Claude starts session:
  1. Load {project}-code_structure repo map (instant)
  2. Include in my system prompt as context
  3. I now know "what exists" in the codebase
  4. Ready to code!
```

### 2. Structural Queries

```
User: "Where is the User authentication defined?"

Claude:
  1. Search code_structure KB (instant)
  2. Find: User#authenticate in app/models/user.rb:45
  3. Return answer immediately
```

### 3. Semantic Queries

```
User: "How does the authentication flow work?"

Claude:
  1. Check if project_index has semantic embeddings
  2. If yes: Semantic search for "authentication flow"
  3. If no: Use repo map + read relevant files directly
  4. Synthesize answer
```

### 4. Adaptive Strategy

```python
def query_codebase(query: str, kb_name: str):
    """
    Smart query routing based on query type.
    """
    if is_needle_query(query):  # "Where is X defined?"
        return search_structural_index(kb_name, query)

    elif has_semantic_index(kb_name):
        return search_semantic_index(kb_name, query)

    else:
        # Fall back to repo map + direct file reads
        repo_map = get_repo_map(kb_name)
        relevant_files = identify_relevant_files(repo_map, query)
        return read_and_synthesize(relevant_files, query)
```

## Updated `/claude-os-init` Flow

**New initialization sequence:**

```
/claude-os-init

1. Gather project info (as before)

2. Create knowledge bases:
   âœ“ {project}-code_structure      # NEW: Structural index
   âœ“ {project}-project_index        # Semantic (selective)
   âœ“ {project}-project_profile
   âœ“ {project}-knowledge_docs
   âœ“ {project}-project_memories

3. Phase 1: Structural Indexing (FAST)
   â†’ "Analyzing codebase structure with tree-sitter..."
   â†’ Parse 10,000 files...
   â†’ Build dependency graph...
   â†’ Compute PageRank scores...
   âœ“ Done in 30 seconds!

   â†’ "Repo map created! You can start coding now."

4. Ask: "Run semantic indexing in background? (optional)"
   [Yes] â†’ Queue background job
   [No]  â†’ Skip, can run later
   [Top 20% only] â†’ Selective indexing (recommended)

5. If background indexing:
   â†’ "Semantic indexing queued (20 minutes estimated)"
   â†’ "You can start coding now, indexing runs in background"
   â†’ Notification when complete

6. Generate CLAUDE.md (as before)

7. Done! Ready to code with instant context.
```

## Performance Comparison

### Before (Current System)

```
example-app Project (10,000 Ruby files):
- Index time: 3-5 hours
- Embeddings: 100,000+ chunks
- Must complete before coding
- High Ollama resource usage
- Blocks productive work
```

### After (Hybrid System)

```
example-app Project (10,000 Ruby files):

Phase 1 (Structural):
- Index time: 30 seconds
- No embeddings needed
- Ready immediately
- Low CPU/memory usage
- âœ“ Can start coding now!

Phase 2 (Semantic, optional):
- Index time: 20-30 minutes (only top 20% + docs)
- Embeddings: ~20,000 chunks (80% reduction)
- Runs in background
- Can code while it runs
- âœ“ Best of both worlds!
```

## Migration Strategy

### New Projects

- Use hybrid indexing by default
- Phase 1 always runs (fast)
- Phase 2 optional but recommended

### Existing Projects

- Add migration command: `/claude-os-reindex`
- Preserves existing semantic index
- Adds structural index alongside
- No data loss

## Success Metrics

- âœ… **Time to first query:** 30 seconds (vs 3-5 hours)
- âœ… **Embedding cost:** 80% reduction (selective indexing)
- âœ… **Context quality:** Equal or better (PageRank scoring)
- âœ… **Query speed:** Faster (structural index is instant)
- âœ… **User satisfaction:** Can start coding immediately

## Future Enhancements

1. **Incremental updates:** Re-index only changed files
2. **Real-time watching:** Auto-update on file changes
3. **Smart re-ranking:** Learn from query patterns
4. **Cross-project patterns:** "I've seen this before in project X"
5. **Team knowledge:** Share structural insights

## References

- [Aider repomap.py implementation](https://github.com/Aider-AI/aider/blob/main/aider/repomap.py)
- [Tree-sitter documentation](https://tree-sitter.github.io/)
- [NetworkX PageRank](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html)
- [py-tree-sitter-languages](https://github.com/grantjenks/py-tree-sitter-languages)

---

**Built by Claude, for Claude, to make Claude unstoppable! ðŸš€**
