# Claude OS Scripts Guide ğŸš€

Quick reference for managing Claude OS services on macOS.

## Quick Start

```bash
# First time setup (installs dependencies)
./scripts/setup_native.sh

# Start all services
./start_all_services.sh

# Restart services
./restart_services.sh

# Stop all services
./stop_all_services.sh
```

---

## Scripts Overview

### 1. `setup_native.sh` - Initial Setup

**When to use:**
- First time setting up Claude OS
- After cloning the repository
- When dependencies are missing

**What it does:**
- âœ… Checks Ollama installation
- âœ… Pulls required AI models (llama3.1, nomic-embed-text)
- âœ… Creates Python virtual environment
- âœ… Installs Python dependencies from `requirements.txt`
- âœ… Creates `data/` directory for SQLite database
- âœ… Creates `logs/` directory for output files
- âœ… Sets up Node.js frontend (if installed)

**Usage:**
```bash
./scripts/setup_native.sh
```

**Output:**
```
ğŸš€ Claude OS Setup - NATIVE (SQLite + Ollama)
==================================================
Step 1: Checking Ollama installation...
  âœ… Ollama found
  âœ… Ollama is running on port 11434
  Checking models... âœ“

Step 2: Pulling required models...
  [models download output...]
  âœ… Models ready

Step 3: Setting up Python environment...
  âœ… Python 3.14 found
  Installing Python dependencies...
  âœ… Python environment ready

Step 4: Creating data directory...
  âœ… Created data/ directory
  âœ… Created logs/ directory

Step 5: Initializing SQLite database...
  âœ… SQLite schema file found
  ğŸ’¾ Database will be created at: data/claude-os.db

Step 6: Setting up Node.js frontend...
  âœ… Node.js v20.x found
  âœ… Frontend dependencies ready

âœ… Claude OS Setup Complete!
```

---

### 2. `start_all_services.sh` - Start Services

**When to use:**
- After setup is complete
- Every time you want to start working
- After stopping services

**What it does:**
- âœ… Checks Ollama is running (starts if needed)
- âœ… Verifies AI models are available
- âœ… Sets up Python environment
- âœ… Creates data directory if missing
- âœ… Starts MCP Server (port 8051)
- âœ… Starts React Frontend (port 5173)
- âœ… Shows URLs and logs

**Usage:**
```bash
./start_all_services.sh
```

**Output:**
```
ğŸš€ Claude OS - Starting All Services
==================================================

1. Checking Ollama...
   âœ“ Ollama is running on port 11434
   Checking models... âœ“

2. Setting up Python environment...
   âœ“ Python environment ready

3. Checking data directory...
   âœ“ data/ directory exists
   âœ“ logs/ directory exists

4. Starting MCP Server...
   Server PID: 12345 (logging to logs/mcp_server.log)
   Waiting for server to start... âœ“

5. Starting React Frontend...
   Frontend PID: 12346 (logging to logs/frontend.log)
   Waiting for frontend to start... âœ“

âœ… All Services Started Successfully!

ğŸ“¡ Service URLs:
   ğŸ¨ Frontend:    http://localhost:5173
   ğŸ”Œ API Server:  http://localhost:8051
   ğŸ“š API Docs:    http://localhost:8051/docs

ğŸ”§ Ollama:
   Host:    http://localhost:11434
   Models:  llama3.1:latest, nomic-embed-text:latest

ğŸ’¾ Database:
   Type:     SQLite (single file)
   Location: data/claude-os.db

ğŸ“ Log Files:
   MCP Server:  logs/mcp_server.log
   Frontend:    logs/frontend.log

ğŸ›‘ To Stop All Services:
   ./stop_all_services.sh

ğŸ”„ To Restart All Services:
   ./restart_services.sh
```

---

### 3. `stop_all_services.sh` - Stop Services

**When to use:**
- When you're done working
- Before restarting
- To free up ports

**What it does:**
- âœ… Stops MCP Server (port 8051)
- âœ… Stops React Frontend (port 5173)
- âœ… Preserves SQLite database
- âœ… Leaves Ollama running (used by other apps)

**Usage:**
```bash
./stop_all_services.sh
```

**Output:**
```
ğŸ›‘ Claude OS - Stopping All Services
==================================================

Stopping ğŸ”Œ MCP Server (port 8051)...
   âœ“ MCP Server stopped (PID: 12345)
Stopping ğŸ¨ React Frontend (port 5173)...
   âœ“ React Frontend stopped (PID: 12346)

âœ… All Claude OS services stopped

â„¹ï¸  Note:
   - Ollama is NOT stopped (may be used by other apps)
   - SQLite database (data/claude-os.db) is preserved

To restart:
   ./restart_services.sh

To start with full setup:
   ./start_all_services.sh
```

---

### 4. `restart_services.sh` - Restart Services

**When to use:**
- After code changes to backend
- When services are behaving strangely
- As a quick restart command

**What it does:**
- âœ… Stops all services
- âœ… Waits for ports to be released
- âœ… Starts all services again

**Usage:**
```bash
./restart_services.sh
```

---

## Common Workflows

### First Time Setup

```bash
# 1. Clone the repo
git clone <repo>
cd claude-os

# 2. Run setup
./scripts/setup_native.sh

# 3. Start services
./start_all_services.sh

# 4. Open browser
open http://localhost:5173
```

### Daily Development

```bash
# Morning: start services
./start_all_services.sh

# Work on features...

# Change backend code?
./restart_services.sh

# Frontend auto-reloads, no restart needed

# End of day: stop services
./stop_all_services.sh
```

### Troubleshooting

```bash
# Check if services are running
lsof -i :5173  # Frontend
lsof -i :8051  # MCP Server

# View logs
tail -f logs/mcp_server.log
tail -f logs/frontend.log

# Restart if something is wrong
./restart_services.sh

# Clear old database and start fresh
rm data/claude-os.db
./start_all_services.sh
```

---

## Ports Used

| Service | Port | Purpose |
|---------|------|---------|
| Frontend | 5173 | React dev server |
| MCP Server | 8051 | API & RAG engine |
| Ollama | 11434 | LLM inference |

---

## Environment Requirements

### macOS
- Ollama (installed via `brew install ollama`)
- Python 3.11+ (`python3 --version`)
- Node.js 18+ (`npm --version`, optional for frontend)

### Files Used

```
data/
  â”œâ”€â”€ claude-os.db          # SQLite database (auto-created)
  â””â”€â”€ uploads/              # User-uploaded documents

logs/
  â”œâ”€â”€ mcp_server.log        # MCP Server logs
  â””â”€â”€ frontend.log          # Frontend logs

venv/                        # Python virtual environment
```

---

## Advanced Usage

### Kill Specific Port

```bash
# Kill process on port 8051
lsof -i :8051 | grep -v COMMAND | awk '{print $2}' | xargs kill -9
```

### View Real-time Logs

```bash
# Watch MCP Server logs
tail -f logs/mcp_server.log

# Watch Frontend logs
tail -f logs/frontend.log

# Follow both
tail -f logs/*.log
```

### Backup Database

```bash
# Create backup
cp data/claude-os.db data/claude-os.db.backup

# Restore from backup
cp data/claude-os.db.backup data/claude-os.db
```

### Reset Everything

```bash
# Stop services
./stop_all_services.sh

# Clear database
rm data/claude-os.db

# Re-setup
./scripts/setup_native.sh

# Start fresh
./start_all_services.sh
```

---

## Tips & Tricks

### ğŸš€ Fast Restart

```bash
# One-liner restart
./stop_all_services.sh && sleep 2 && ./start_all_services.sh
```

### ğŸ“Š Monitor Resources

```bash
# Watch CPU/Memory usage
top -o %CPU

# Watch Ollama model usage
ollama ps
```

### ğŸ”§ Debug Mode

```bash
# Run server directly (no background)
source venv/bin/activate
cd mcp_server
python server.py
```

### ğŸ¨ Frontend Development

```bash
# Frontend auto-reloads on file changes
# No restart needed for React components
# Only restart for Python changes
```

---

## Troubleshooting

### "Port already in use"

```bash
# Check what's using the port
lsof -i :8051

# Kill the process
kill -9 <PID>

# Or use our stop script
./stop_all_services.sh
```

### "Ollama is not running"

```bash
# Check status
ollama ps

# Start Ollama
brew services start ollama

# Or manually
ollama serve
```

### "Module not found" errors

```bash
# Reinstall dependencies
source venv/bin/activate
pip install -r requirements.txt
```

### Database corrupted?

```bash
# Backup old database
mv data/claude-os.db data/claude-os.db.old

# Restart (creates new database)
./start_all_services.sh

# Restore if needed
mv data/claude-os.db.old data/claude-os.db
```

---

## Support

Check logs for errors:
```bash
tail -50 logs/mcp_server.log
tail -50 logs/frontend.log
```

For issues:
1. Check logs
2. Try `./restart_services.sh`
3. Try `./scripts/setup_native.sh` again
4. Check if Ollama is running: `ollama ps`

---

**Ready to go!** ğŸš€

Next: Open http://localhost:5173 and start building! ğŸ’ª
