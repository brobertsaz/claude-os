# Claude OS

```text
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•‘ â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
â•‘ â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•‘ â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘
â•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
â•‘  â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•
â•‘                                                               â•‘
â•‘           Localized Multi-Knowledge-Base RAG System           â•‘
â•‘                    with MCP Integration                       â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

> **Production-grade RAG system** with SQLite vector search, Ollama LLMs, and Model Context Protocol. Runs 100% locally on your machine.

[![License: MIT](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![SQLite](https://img.shields.io/badge/SQLite-3.0+-green.svg)](https://www.sqlite.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Latest-pink.svg)](https://ollama.ai/)

---

## ğŸš€ What is Claude OS?

**Claude OS** is a **localized RAG (Retrieval-Augmented Generation) system** designed to make AI assistants deeply knowledgeable about your codebase and documentation. It combines:

- **ğŸ—„ï¸ SQLite + sqlite-vec** - Lightweight vector database for semantic search
- **ğŸ¤– Ollama** - Local LLMs (llama3.1) with no API keys needed
- **ğŸ”Œ MCP Integration** - Claude Desktop integration via Model Context Protocol
- **âš¡ React UI** - Modern dashboard for managing knowledge bases
- **ğŸ“š Multi-KB Support** - Separate knowledge bases for different projects
- **ğŸ§  Advanced RAG** - Hybrid search, reranking, and agentic modes

### Perfect For

âœ… Making Claude deeply familiar with your codebase
âœ… Private, secure knowledge base (never leaves your machine)
âœ… Team collaboration (share with coworkers easily)
âœ… Integration with Claude Desktop via MCP
âœ… Building AI-assisted development workflows

---

## âš¡ Quick Start (5-10 minutes)

### Prerequisites

**You MUST have these installed first:**

1. **Python 3.11+** (required)
   ```bash
   python3 --version
   ```
   - macOS: `brew install python@3.11`
   - Linux: `sudo apt-get install python3.11`
   - Windows: Download from https://www.python.org/downloads/

2. **Git** (required)
   ```bash
   git --version
   ```
   - macOS: `brew install git`
   - Linux: `sudo apt-get install git`
   - Windows: Download from https://git-scm.com/

3. **Node.js 16+** (optional, for React frontend)
   ```bash
   node --version
   ```
   - macOS: `brew install node`
   - Linux: `sudo apt-get install nodejs`
   - Windows: Download from https://nodejs.org/

---

### One-Line Installer âœ¨

**Once you have Python 3.11+ and Git, run this command:**

```bash
curl -fsSL https://raw.githubusercontent.com/brobertsaz/claude-os/main/setup.sh | bash
```

**The script will automatically:**
- âœ… Install Ollama (if needed) + download LLM models
- âœ… Install Redis (if needed) for caching/queues
- âœ… Set up Python virtual environment
- âœ… Install all Python dependencies
- âœ… Create SQLite database
- âœ… Install frontend dependencies (if Node.js present)

**Then start services:**
```bash
./start_all_services.sh
```

**Done!** Visit http://localhost:5173 to start using Claude OS.

### Installation (Step by Step)

**Step 1: Install Prerequisites** (one-time only)

Choose your OS:

**macOS:**
```bash
# Install Python 3.11
brew install python@3.11

# Install Git
brew install git

# Optional: Install Node.js for frontend
brew install node
```

**Linux (Ubuntu/Debian):**
```bash
# Install Python 3.11
sudo apt-get update
sudo apt-get install python3.11 python3.11-venv

# Install Git
sudo apt-get install git

# Optional: Install Node.js for frontend
sudo apt-get install nodejs npm
```

**Verify installation:**
```bash
python3 --version  # Should be 3.11+
git --version      # Should exist
```

---

**Step 2: Run the Installer**

Once you have Python 3.11+ and Git:

```bash
curl -fsSL https://raw.githubusercontent.com/brobertsaz/claude-os/main/setup.sh | bash
```

This automatically installs:
- âœ… **Ollama** - LLM engine (auto-installed if missing)
- âœ… **Redis** - Cache & queues (auto-installed if missing)
- âœ… **Python dependencies** - All required packages
- âœ… **SQLite database** - Local vector store
- âœ… **Frontend** - React UI (if Node.js present)

The script will download ~5-10 GB of LLM models (llama3.1, embeddings).

---

**Step 3: Start Services**

```bash
./start_all_services.sh
```

This starts:
- ğŸ”Œ **MCP Server** (port 8051) - Backend RAG engine
- ğŸ¨ **React UI** (port 5173) - Web dashboard
- ğŸ¤– **Ollama** (port 11434) - LLM service
- ğŸ’¾ **Redis** (port 6379) - Cache & queues
- ğŸ§  **RQ Workers** - Real-time learning system

---

**Step 4: Access the Application**

Open your browser and visit:
- **Frontend:** http://localhost:5173
- **API Docs:** http://localhost:8051/docs

Start uploading documents to create knowledge bases!

---

## ğŸ¯ Initialize Your Project (The Magic Sauce âœ¨)

Once Claude OS is running, follow these 3 simple steps to make Claude an expert on your codebase:

### Step 1: Create a Project in Claude OS UI

1. **Open the UI** - Visit http://localhost:5173 in your browser
2. **Click "Create Project"** button
3. **Fill in the form:**
   - **Project Name** - e.g., "my-awesome-app"
   - **Project Path** - Select your project directory (e.g., `/Users/you/Projects/my-awesome-app`)
   - **Description** - (optional) Brief description of your project

4. **Click "Create Project"**

Your project is now registered in Claude OS!

### Step 2: Get Your Project ID

After creating your project, you'll see it listed in the Projects view. The **Project ID** is displayed right on the project card (e.g., `#1`, `#2`, etc.).

Simply note the number - that's your project ID!

**Example:**
- If you see `#1` on your project card, your project ID is `1`
- If you see `#3` on your project card, your project ID is `3`

### Step 3: Initialize Project with Claude Code

This is where the magic happens! The initialization will:
- âœ… Analyze your entire codebase (5 minutes)
- âœ… Generate coding standards & architecture docs
- âœ… Index 50 key files (~800 code chunks)
- âœ… Set up Git hooks for auto-indexing
- âœ… Create 4 Knowledge Bases automatically

**In Claude Code, run:**

```bash
/initialize-project [project-id]
```

**Example:**
```bash
/initialize-project 1
```

**What happens:**
- Claude analyzes your project structure, patterns, and conventions
- Generates `CODING_STANDARDS.md`, `ARCHITECTURE.md`, `DEVELOPMENT_PRACTICES.md`
- Creates semantic indexes for instant retrieval
- Installs Git hooks to keep knowledge up-to-date

**After 5 minutes:**
âœ… Claude is now an expert on your project!

---

## ğŸ”Œ MCP Integration with Claude Desktop

To use your knowledge bases with Claude Desktop:

### Option 1: Via CLI (Easiest)

```bash
# Add PISTN knowledge base to Claude Desktop
claude mcp add pistn http://localhost:8051/mcp/kb/pistn

# Add PISTN Agent OS knowledge base
claude mcp add pistn-agent-os http://localhost:8051/mcp/kb/pistn-agent-os
```

Then in Claude Desktop, your knowledge bases are available as built-in tools. Ask Claude about your codebase directly!

### Option 2: Manual Configuration

Edit `~/.claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "pistn": {
      "url": "http://localhost:8051/mcp/kb/pistn"
    },
    "pistn-agent-os": {
      "url": "http://localhost:8051/mcp/kb/pistn-agent-os"
    }
  }
}
```

Then restart Claude Desktop.

---

## ğŸ“š Managing Knowledge Bases

### Create a Knowledge Base

1. Visit http://localhost:5173
2. Click "Create Knowledge Base"
3. Choose type:
   - **GENERIC** - General documentation
   - **CODE** - Source code repositories
   - **DOCUMENTATION** - Technical docs
   - **AGENT_OS** - Spec-driven development

### Upload Documents

1. Select a knowledge base
2. Click "Upload Documents"
3. Choose files (supports .md, .txt, .pdf, .py, .js, .ts, .json, .yaml)
4. Watch as documents are indexed

### Query the Knowledge Base

**Via Web UI:**
1. Select a KB from the dropdown
2. Type your question
3. View answer with source citations

**Via Claude Desktop:**
Once added as MCP server, Claude can query automatically when working on your project.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Claude Desktop                      â”‚
â”‚         (or any MCP client)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ MCP HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         MCP Server (Port 8051)                   â”‚
â”‚              FastAPI Backend                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Engine       â”‚  â”‚  React UI         â”‚
â”‚  (llama-index)     â”‚  â”‚  (Port 5173)      â”‚
â”‚  â€¢ Vector Search   â”‚  â”‚                   â”‚
â”‚  â€¢ Hybrid Search   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Reranking       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite + sqlite-vec (Local Database)         â”‚
â”‚  â€¢ knowledge_bases                             â”‚
â”‚  â€¢ documents (with embeddings)                 â”‚
â”‚  â€¢ Single-file database                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Ollama        â”‚
                    â”‚  (Port 11434)  â”‚
                    â”‚ â€¢ llama3.1     â”‚
                    â”‚ â€¢ Embeddings   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configuration

### Environment Variables

The system uses sensible defaults, but you can customize via environment variables:

```bash
# SQLite Database
SQLITE_DB_PATH=data/claude-os.db  # Default: data/claude-os.db

# Ollama
OLLAMA_HOST=http://localhost:11434  # Default: localhost:11434
OLLAMA_MODEL=llama3.1:latest        # Default: llama3.1:latest

# MCP Server
MCP_SERVER_HOST=0.0.0.0         # Default: 0.0.0.0
MCP_SERVER_PORT=8051            # Default: 8051
```

---

## ğŸ“Š Performance

**Native Ollama Setup (Current)**
- Response time: ~40 seconds per query
- GPU acceleration: Full Metal GPU on Apple Silicon
- Memory usage: 8-10GB (models + context)
- CPU usage: 12 cores (M4 Pro, leaves 2 for system)

**Why it's fast:**
- Direct GPU acceleration (no virtualization)
- Efficient vector search in SQLite
- Optimized RAG engine with caching
- Single-file database with minimal overhead

---

## ğŸ› ï¸ Scripts Guide

Claude OS includes comprehensive shell scripts for setup, service management, and testing. Here's what each one does:

### Installation & Setup

#### `./setup.sh` - Complete Setup â­ **USE THIS ONE**
```bash
./setup.sh
```
**This is the standard setup script that 99% of users need.**

**Prerequisites (must be installed first):**
- âœ… Python 3.11+ (required - script will fail if missing)
- âœ… Git (required - script will fail if missing)
- âš ï¸ Node.js 16+ (optional - script skips frontend if missing)

**What it automatically installs:**
- âœ… **Ollama** - Downloads and starts if not installed
- âœ… **Redis** - Installs and starts if not present
- âœ… **Python virtual environment** - Isolated environment
- âœ… **Python dependencies** - All packages from `requirements.txt`
- âœ… **LLM models** - llama3.1 and nomic-embed-text (~5-10 GB)
- âœ… **SQLite database** - Local vector store
- âœ… **Frontend dependencies** - npm packages (if Node.js present)

**Supported platforms:** macOS & Linux

**When to use:**
- âœ… **First-time setup (recommended for 99% of users)**
- âœ… You have Python 3.11+ and Git already installed
- âœ… You don't have Ollama or Redis yet
- âœ… You want a complete, automated setup
- âœ… You're on any Unix system (macOS/Linux)

---

#### `./setup_native.sh` - Fast macOS Setup (Advanced Users Only)
```bash
./setup_native.sh
```
**This is an optional lightweight setup for macOS users who already have Ollama installed via Homebrew.**

**What it does:**
- âœ… Verifies Ollama is already installed via Homebrew (fails if not)
- âœ… Pulls required LLM models (llama3.1, nomic-embed-text)
- âœ… Sets up Python virtual environment
- âœ… Installs Python dependencies
- âœ… Creates data/ and logs/ directories
- âœ… Initializes SQLite database
- âš ï¸ Does NOT install Redis

**When to use (rare):**
- âš ï¸ Only if you already have **Ollama installed via `brew install ollama`**
- âš ï¸ You're on macOS only
- âš ï¸ You already have Redis running separately

**Note:** Most users should use `./setup.sh` instead. Only use this if you know what you're doing.

---

### Service Management

#### `./start_all_services.sh` - Start Everything
```bash
./start_all_services.sh
```
**Starts:**
- ğŸ”Œ **MCP Server** (port 8051) - Backend RAG engine
- ğŸ¨ **React Frontend** (port 5173) - Web dashboard
- ğŸ¤– **RQ Workers** - Real-time learning system
- ğŸ’¾ **Redis** - Cache & message queue
- ğŸ§  **Ollama** - LLM service

**Features:**
- Automatic health checks for all services
- Creates required directories if missing
- Checks that ports are free
- Logs all services to `logs/` directory
- Shows service URLs and PIDs

**Output:**
```
Service URLs:
  ğŸ¨ Frontend:    http://localhost:5173
  ğŸ”Œ API Server:  http://localhost:8051
  ğŸ“š API Docs:    http://localhost:8051/docs

Log Files:
  MCP Server:   logs/mcp_server.log
  Frontend:     logs/frontend.log
  RQ Workers:   logs/rq_workers.log
```

---

#### `./stop_all_services.sh` - Stop All Services
```bash
./stop_all_services.sh
```
**Stops:**
- ğŸ”Œ MCP Server (port 8051)
- ğŸ¨ React Frontend (port 5173)
- ğŸ¤– RQ Workers (real-time learning)
- ğŸ’¾ Redis

**Note:** Ollama is preserved (may be used by other apps)

---

#### `./restart_services.sh` - Restart Everything
```bash
./restart_services.sh
```
**Does:**
1. Stops all services gracefully
2. Waits for ports to be released (3 second delay)
3. Starts all services fresh

**Use when:** Code changes aren't reflected or services need a clean restart

---

#### `./start_mcp_server.sh` - Start Only MCP Server
```bash
./start_mcp_server.sh
```
**Starts:**
- ğŸ”Œ MCP Server (port 8051)

**Checks:**
- âœ… Ollama is running
- âœ… SQLite database exists
- âœ… Python environment is ready

**Use when:** You only need the backend API (e.g., for testing)

---

#### `./start_redis_workers.sh` - Start RQ Workers
```bash
./start_redis_workers.sh
```
**Starts:**
- ğŸ¤– RQ Workers for real-time learning system
- Listening on queues: `claude-os:learning`, `claude-os:prompts`, `claude-os:ingest`
- Scheduler for periodic tasks

**Checks:**
- âœ… Redis is running
- âœ… Python virtual environment exists
- âœ… RQ dependencies are installed

**Use when:** Running the real-time learning system separately

---

### Testing

#### `./run_tests.sh` - Run Test Suite
```bash
./run_tests.sh [OPTIONS]
```

**Options:**
```bash
./run_tests.sh                    # Run all tests
./run_tests.sh --unit             # Unit tests only
./run_tests.sh --integration      # Integration tests only
./run_tests.sh --vector           # Vector DB tests
./run_tests.sh --rag              # RAG engine tests
./run_tests.sh --api              # API endpoint tests
./run_tests.sh --coverage         # Generate coverage report
./run_tests.sh --verbose          # Detailed output
./run_tests.sh --unit --coverage  # Combine options
```

**Features:**
- Validates PostgreSQL connection
- Creates test database if needed
- Shows test configuration
- Generates HTML coverage report (with `--coverage`)

---

## ğŸ“ Project Structure

```
claude-os/
â”œâ”€â”€ app/                    # Backend application
â”‚   â”œâ”€â”€ core/              # Core modules
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration management
â”‚   â”‚   â”œâ”€â”€ sqlite_manager.py  # SQLite interface
â”‚   â”‚   â”œâ”€â”€ rag_engine.py  # RAG logic
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ db/                # Database schemas
â”‚   â””â”€â”€ ...
â”œâ”€â”€ frontend/              # React UI (Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ mcp_server/           # MCP Server (HTTP)
â”‚   â”œâ”€â”€ server.py         # FastAPI + MCP endpoints
â”‚   â””â”€â”€ ...
â”œâ”€â”€ migrations/           # Database migrations
â”œâ”€â”€ data/                 # SQLite database (auto-created)
â”‚   â””â”€â”€ claude-os.db
â”œâ”€â”€ logs/                 # Service logs (auto-created)
â”œâ”€â”€ .sh scripts           # Utility scripts (see Scripts Guide above)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # This file
```

---

## ğŸ› Troubleshooting

### Database Issues

The SQLite database is automatically created at `data/claude-os.db`. If you encounter issues:

```bash
# Check if database exists
ls -lh data/claude-os.db

# Remove and recreate (WARNING: deletes all data)
rm data/claude-os.db
# Restart the server to recreate
```

### Ollama Issues

```bash
# Check if Ollama is running
ollama list

# Start Ollama manually
ollama serve

# Check for specific model
ollama list | grep llama3.1
```

### Port Already in Use

```bash
# Find process on port 8051 (MCP Server)
lsof -i :8051

# Find process on port 5173 (React UI)
lsof -i :5173

# Kill if needed (replace PID with actual process ID)
kill -9 <PID>
```

### MCP Server Not Starting

```bash
# Check logs
tail -f /tmp/mcp_server.log

# Verify Python environment
source venv/bin/activate
python mcp_server/server.py

# Check port 8051 is accessible
curl http://localhost:8051/health
```

---

## ğŸ“– Additional Documentation

### Core Features
- **[docs/SELF_LEARNING_SYSTEM.md](docs/SELF_LEARNING_SYSTEM.md)** - ğŸ§  How Claude learns from your conversations automatically
- **[docs/REAL_TIME_LEARNING_GUIDE.md](docs/REAL_TIME_LEARNING_GUIDE.md)** - Real-time learning system usage guide
- **[docs/MEMORY_MCP_GUIDE.md](docs/MEMORY_MCP_GUIDE.md)** - Persistent memory across sessions

### Technical Documentation
- **[README_NATIVE_SETUP.md](README_NATIVE_SETUP.md)** - Detailed native setup guide
- **[NATIVE_VS_DOCKER_DECISION.md](NATIVE_VS_DOCKER_DECISION.md)** - Why we chose native Ollama
- **[PERFORMANCE_TEST_RESULTS.md](PERFORMANCE_TEST_RESULTS.md)** - Benchmark results
- **[SLUG_IMPLEMENTATION_SUMMARY.md](SLUG_IMPLEMENTATION_SUMMARY.md)** - URL slug system
- **[MCP_KB_ENDPOINTS.md](MCP_KB_ENDPOINTS.md)** - MCP endpoint documentation

---

## ğŸ¤ Contributing

This is a personal development tool. Feel free to:
- Modify for your specific needs
- Add new KB types
- Optimize RAG strategies
- Contribute improvements back

---

## ğŸ“„ License

MIT License - Use it freely!

---

## ğŸ¯ Next Steps

1. **First-time setup:** Run `./setup_native.sh`
2. **Start services:** Run `./start_all_services.sh`
3. **Create knowledge base:** Visit http://localhost:5173
4. **Upload documents:** Add your codebase/docs
5. **Integrate with Claude:** Run `claude mcp add ...`
6. **Start coding:** Ask Claude about your project!

Happy coding! ğŸš€

